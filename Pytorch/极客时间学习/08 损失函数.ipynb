{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6acb2f76-9ca1-4ede-84ff-89f1dec57954",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb0bbf-60a1-49d8-8268-5bc972a31193",
   "metadata": {},
   "source": [
    "# MSE\n",
    "\n",
    "MSE 是一种常用的 回归问题 损失函数，用来衡量预测值和真实值之间的差距。\n",
    "公式如下：\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2\n",
    "$$\n",
    "\n",
    "- \\( y_i \\)：真实值  \n",
    "- \\( \\hat{y_i} \\)：预测值  \n",
    "- \\( n \\)：样本数量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9ec0b3-5247-4fb9-9380-b00086cc6789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义真实值和预测值\n",
    "y_true = torch.tensor([3.0, 5.0, 7.0])\n",
    "y_pred = torch.tensor([2.0, 6.0, 8.0])\n",
    "\n",
    "# 定义MSE损失函数\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# 计算损失\n",
    "loss = mse_loss(y_pred, y_true)\n",
    "print(\"MSE Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f0541-b618-44d8-8910-d36b19ca2818",
   "metadata": {},
   "source": [
    "而平均绝对误差损失函数（Mean Absolute Error, MAE）是另一种常用于回归问题的损失函数，它的目标是度量真实值和预测值差异的绝对值之和，定义如下:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y_i} \\right|\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209ddb1-f730-46d2-9c6d-141bb1bb7392",
   "metadata": {},
   "source": [
    "# 交叉熵损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a78b55-70ff-413a-830a-d2d36ab7217f",
   "metadata": {},
   "source": [
    "熵最开始是物理学中的一个术语，它表示了一个系统的混乱程度或者说无序程度。如果一个系统越混乱，那么它的熵越大。信息论创始人香农把这个概念引申到信道通信的过程中，开创了信息论，所以这里的熵又称为信息熵。信息熵的公式化可以表示为：\n",
    "\n",
    "$$\n",
    "H(p) = - \\sum_{i} p(x_i) \\log p(x_i)\n",
    "$$\n",
    "\n",
    "\n",
    "其中，x 表示随机变量，与之相对应的是所有可能输出的集合。P(x) 表示输出概率函数。变量的不确定性越大，熵也就越大，把变量搞清楚所需要的信息量也就越大。\n",
    "\n",
    "\n",
    "当我们将函数变为如下格式，将 log p 改为 log q，即：\n",
    "\n",
    "$$\n",
    "- \\sum_{i=1}^{n} p(x_i) \\log \\big( q(x_i) \\big)\n",
    "$$\n",
    "\n",
    "\n",
    "其中，𝑝(𝑥) 表示真实概率分布，𝑞(𝑥) 表示预测概率分布。这个函数就是交叉熵损失函数（Cross entropy loss）。也就意味着，这个公式同时衡量了真实概率分布和预测概率分布两方面。所以，这个函数实际上就是通过衡量并不断去尝试缩小两个概率分布的误差，使预测的概率分布尽可能达到真实概率分布。\n",
    "\n",
    "\n",
    "### 举个例子\n",
    "\n",
    "三分类问题：\n",
    "\n",
    "- 真实标签：第 2 类 → \\( p = [0, 1, 0] \\)  \n",
    "- 模型预测：\\( q = [0.2, 0.7, 0.1] \\)  \n",
    "\n",
    "交叉熵损失：  \n",
    "\n",
    "$$\n",
    "Loss = - (1 \\cdot \\log 0.7) = -\\log 0.7 \\approx 0.357\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "如果预测错了，比如 \\( q = [0.8, 0.1, 0.1] \\)，  \n",
    "\n",
    "$$\n",
    "Loss = -\\log 0.1 \\approx 2.302\n",
    "$$\n",
    "\n",
    "损失就会变大\n",
    "\n",
    "\n",
    "### 直观理解\n",
    "\n",
    "如果模型预测正确类别的概率很大（接近 1），损失就很小。\n",
    "如果模型预测正确类别的概率很小（接近 0），损失就很大（趋近于无穷大）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472a2a1-d7fa-41be-ad12-83a9683b3b15",
   "metadata": {},
   "source": [
    "# softmax 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdbe15-a2dc-4187-b306-cb9cddbb8f95",
   "metadata": {},
   "source": [
    "softmax 是深度学习中使用非常频繁的一个函数。在某些场景下，一些数值大小范围分布非常广，而为了方便计算，或者使梯度更好的更新（后续我们还会学习梯度更新），我们需要把输入的这些数值映射为 0-1 之间的实数，并且归一化后能够保证几个数的和为 1。\n",
    "\n",
    "\n",
    "公式：\n",
    "\n",
    "$$\n",
    "q_i = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n",
    "$$\n",
    "\n",
    "- \\( z_i \\)：模型对类别 \\( i \\) 的输出分数（logit）  \n",
    "- \\( q_i \\)：归一化后类别 \\( i \\) 的概率  \n",
    "- 所有 \\( q_i \\) 相加 = 1\n",
    "\n",
    "\n",
    "例子：\n",
    "如果模型输出 logits = [2.0, 1.0, 0.1],\n",
    "Softmax 会转成概率： [0.65, 0.24, 0.11]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14d037-5dea-42ee-bfa5-5333545ad299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8163e09-5515-424f-9bb7-9b85092ab442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c6401-a6dd-47cc-bf31-40e674b3c9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ea26d-b007-4112-9a9f-31775aac0651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
