{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22784515-e107-4546-ab79-ac0b96477260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "912c81f2-5420-49c4-b94d-c7a7b595e26c",
   "metadata": {},
   "source": [
    "先随机生成训练集 X 与对应的标签 Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd58e3a5-4bd4-42f3-81fc-5b58baf3f46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10bc00690>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "w = 2\n",
    "b = 3\n",
    "xlim = [-10, 10]\n",
    "x_train = np.random.randint(low=xlim[0], high=xlim[1], size=30)\n",
    "\n",
    "y_train = [w * x + b + random.randint(0,2) for x in x_train]\n",
    "\n",
    "plt.plot(x_train, y_train, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "394ce3d2-dc5d-4202-a269-81520d7fe40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LinearModel(nn.Module):  #必须继承 nn.Module 类\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    #通常来说要把有需要学习的参数的层放到构造函数中\n",
    "    self.weight = nn.Parameter(torch.randn(1))\n",
    "    self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "  def forward(self, input): #forward()前向传播 是必须重写的方法\n",
    "    return (input * self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bab19b5-de98-420f-b511-57732b2ae644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)  #优化器（Optimizer）就是一个根据梯度信息自动更新模型参数的算法。\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32) #把原本的 NumPy或Python数据（y_train）转成 PyTorch张量（Tensor），\n",
    "for _ in range(1000):\n",
    "    input = torch.from_numpy(x_train)\n",
    "    output = model(input)\n",
    "    loss = nn.MSELoss()(output, y_train)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff544f2f-25f9-43b1-a1b8-2a6b2f19ee0b",
   "metadata": {},
   "source": [
    "优化器：\n",
    "\n",
    "| 参数名                  | 含义                 | 举例解释                         |\n",
    "| -------------------- | ------------------ | ---------------------------- |\n",
    "| `model.parameters()` | 告诉优化器要更新哪些参数       | 就是 model 的 `weight` 和 `bias` |\n",
    "| `lr=1e-4`            | 学习率（learning rate） | 一次走多大步，下山步幅                  |\n",
    "| `momentum=0.9`       | 动量                 | 让梯度更新更平滑，不会左右乱晃              |\n",
    "| `weight_decay=1e-2`  | 权重衰减（L2正则化）        | 防止参数太大导致过拟合                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a58681-2b01-44a3-8997-d16c711db2b4",
   "metadata": {},
   "source": [
    "优化器的工作流程:\n",
    "\n",
    "for _ in range(1000):\n",
    "\n",
    "    output = model(input)         # 1️⃣ 前向传播\n",
    "    \n",
    "    loss = nn.MSELoss()(output, y_train)  # 2️⃣ 计算损失\n",
    "    \n",
    "    model.zero_grad()             # 3️⃣ 清空旧梯度\n",
    "    \n",
    "    loss.backward()               # 4️⃣ 反向传播，计算梯度\n",
    "    \n",
    "    optimizer.step()              # 5️⃣ 优化器更新参数 ✅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f907fce1-5249-4bff-99aa-10f1a4622644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', Parameter containing:\n",
      "tensor([2.0042], requires_grad=True))\n",
      "('bias', Parameter containing:\n",
      "tensor([3.3131], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "#model.named_parameters() 会遍历模型中所有可训练参数（learnable parameters）\n",
    "\n",
    "for parameter in model.named_parameters():    \n",
    "  print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b30b1c-da9b-4d52-a884-13e27b2c68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个新的神经网络层：输入 → Conv2d(输入通道→3) → Conv2d(3→输出通道) → 输出\n",
    "\n",
    "\n",
    "class CustomLayer(nn.Module):\n",
    "  def __init__(self, input_channels, output_channels):\n",
    "    super().__init__()\n",
    "    self.conv1_1 = nn.Conv2d(in_channels=input_channels, out_channels=3, kernel_size=3, padding='same')\n",
    "    self.conv1_2 = nn.Conv2d(in_channels=3, out_channels=output_channels, kernel_size=2, padding='same')\n",
    "    \n",
    "  def forward(self, input):\n",
    "    x = self.conv1_1(input)\n",
    "    x = self.conv1_2(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f99558-1d16-48fb-8063-c910fae6ac69",
   "metadata": {},
   "source": [
    "解释：\n",
    "\n",
    "第一层卷积：\n",
    "\n",
    "self.conv1_1 = nn.Conv2d(\n",
    "    in_channels=input_channels,   # 输入特征图的通道数（如RGB是3）\n",
    "    out_channels=3,               # 输出通道数=3\n",
    "    kernel_size=3,                # 卷积核大小 3x3\n",
    "    padding='same'                # 保持输入输出尺寸相同\n",
    ")\n",
    "\n",
    "\n",
    "👉 意思是：\n",
    "第一个卷积层接收输入通道数为 input_channels（例如图像3通道），\n",
    "输出3个通道的特征图。\n",
    "\n",
    "padding='same' 表示自动补零，让输出尺寸和输入一样大。\n",
    "\n",
    "第二层卷积\n",
    "\n",
    "self.conv1_2 = nn.Conv2d(\n",
    "    in_channels=3,                # 上一层输出通道=3\n",
    "    out_channels=output_channels, # 输出通道=你设定的值\n",
    "    kernel_size=2,\n",
    "    padding='same'\n",
    ")\n",
    "\n",
    "\n",
    "👉 意思是：\n",
    "第二层卷积从上一层的3个通道输入，\n",
    "输出 output_channels 个通道的特征图（比如64、128等）。\n",
    "\n",
    "\n",
    "\n",
    "def forward(self, input):\n",
    "    x = self.conv1_1(input)   # 第一次卷积\n",
    "    x = self.conv1_2(x)       # 第二次卷积\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d982d-f67d-40e2-b203-8099a1df7a8b",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecc70d-cd8c-4179-b44c-7ac9f4346b9e",
   "metadata": {},
   "source": [
    "## 只保存训练好的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca9c976-ef6c-4eed-8656-db1d5912e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './linear_model.pth')   #第一个参数是模型的 state_dict，而第二个参数要保存的位置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad055600-ab08-495e-83b0-73dab1b8096d",
   "metadata": {},
   "source": [
    "代码中的 state_dict 是一个字典，在模型被定义之后会自动生成，存储的是模型可训练的参数。我们可以打印出线性回归模型的 state_dict，如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f977ea-a693-4112-935f-275a03abf869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([2.0042])), ('bias', tensor([3.3131]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b441f1ef-7a22-47ce-a41e-890b06865945",
   "metadata": {},
   "source": [
    "加载模型的方式如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9410db9-cc53-495b-8785-b42400be7af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', Parameter containing:\n",
      "tensor([2.0042], requires_grad=True))\n",
      "('bias', Parameter containing:\n",
      "tensor([3.3131], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "# 先定义网络结构\n",
    "linear_model = LinearModel()\n",
    "# 加载保存的参数\n",
    "linear_model.load_state_dict(torch.load('./linear_model.pth'))\n",
    "linear_model.eval()\n",
    "for parameter in linear_model.named_parameters():\n",
    "  print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491fac66-4040-4922-8116-e00bc335e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision.models import AlexNet_Weights\n",
    "\n",
    "# 使用新写法加载预训练模型\n",
    "alexnet = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "# 或者使用默认权重\n",
    "# alexnet = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46edc451-93ff-4763-8cc9-3229c904cb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(264)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "im = Image.open('dog.webp')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "input_tensor = transform(im).unsqueeze(0)\n",
    "alexnet(input_tensor).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e8eda7-5a79-4e1f-811b-64930171847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papillon\n"
     ]
    }
   ],
   "source": [
    "# 157类是什么\n",
    "\n",
    "from torchvision.models import AlexNet_Weights\n",
    "\n",
    "weights = AlexNet_Weights.IMAGENET1K_V1\n",
    "categories = weights.meta[\"categories\"]\n",
    "\n",
    "print(categories[157])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0dbc1e-d977-4220-841d-ffbb83fab4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bc7e3-14f1-4e3d-b7f3-b5ded408a19c",
   "metadata": {},
   "source": [
    "# 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4beef-c1ab-4e09-8f3a-3f99f8f9c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 1/3 | train_loss=1.0278 acc=0.6336 | val_loss=0.6252 acc=0.7785\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PyTorch 微调（Fine-tuning）AlexNet 简单示例（含 Apple MPS 加速）\n",
    "--------------------------------------------------\n",
    "功能：\n",
    "1. 使用 torchvision 自带的 AlexNet 预训练模型；\n",
    "2. 冻结特征提取层（features），只训练分类器层；\n",
    "3. 在 CIFAR-10 数据集上进行微调；\n",
    "4. 优先使用 Apple MPS（Metal），其次 CUDA，最后 CPU；\n",
    "5. 半精度 autocast（MPS/CUDA），自动下载数据与权重；\n",
    "6. 保存微调后的模型。\n",
    "\n",
    "运行环境（建议）：\n",
    "pip install torch torchvision\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# ============================================================\n",
    "# 1. 环境设置（优先使用 MPS，其次 CUDA）\n",
    "# ============================================================\n",
    "use_mps = torch.backends.mps.is_available() and torch.backends.mps.is_built()\n",
    "if use_mps:\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# （可选）macOS 上 DataLoader 建议使用 spawn\n",
    "try:\n",
    "    import torch.multiprocessing as mp\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "# 是否启用 channels_last 加速（对 CNN 有时更快；若遇到不支持的算子可设为 False）\n",
    "USE_CHANNELS_LAST = True\n",
    "\n",
    "# ============================================================\n",
    "# 2. 加载预训练模型并冻结特征提取层\n",
    "# ============================================================\n",
    "# 从官方加载 ImageNet 预训练的 AlexNet 权重\n",
    "model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# 冻结特征提取层的参数（即卷积部分 features）\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 替换最后的全连接层，使输出类别数 = CIFAR10 的 10 类\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, 10)\n",
    "\n",
    "# 把模型放到相应设备\n",
    "model = model.to(device)\n",
    "\n",
    "# 可选：channels_last\n",
    "if USE_CHANNELS_LAST and device != \"cpu\":\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "# ============================================================\n",
    "# 3. 数据准备（使用 AlexNet 权重自带的标准化参数）\n",
    "# ============================================================\n",
    "# 由于 AlexNet 是在 ImageNet 上训练的，输入大小应为 224×224\n",
    "# transforms 包括 Resize、Crop、Normalize 等；权重自带的 transforms 含 ToTensor+Normalize\n",
    "weight_tf = AlexNet_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize(256),           # 调整短边到 256\n",
    "    transforms.CenterCrop(224),       # 中心裁剪到 224×224\n",
    "    transforms.RandAugment(),         # 随机数据增强（可删除以进一步提速）\n",
    "    weight_tf,                        # 包含 ToTensor + Normalize\n",
    "])\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    weight_tf,\n",
    "])\n",
    "\n",
    "# 自动下载 CIFAR10 数据集\n",
    "data_root = \"./data\"\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "train_ds = datasets.CIFAR10(root=data_root, train=True, download=True, transform=train_tf)\n",
    "test_ds  = datasets.CIFAR10(root=data_root, train=False, download=True, transform=test_tf)\n",
    "\n",
    "# 创建数据加载器（pin_memory 对 CUDA 有效，MPS/CPU 下关闭）\n",
    "pin = True if device == \"cuda\" else False\n",
    "num_workers = 2  # 可根据 CPU 核心数调整（2~4 较合适）\n",
    "batch_size_train = 64   # M 系列统一内存有限，如 OOM 可降到 32\n",
    "batch_size_test  = 128  # 可酌情调整\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size_train, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=pin)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size_test, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=pin)\n",
    "\n",
    "# ============================================================\n",
    "# 4. 定义优化器和损失函数\n",
    "# ============================================================\n",
    "# 只优化 requires_grad=True 的参数（分类器层）\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                              lr=2e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ============================================================\n",
    "# 5. AMP / autocast 上下文（MPS/CUDA 半精度）\n",
    "# ============================================================\n",
    "if device == \"mps\":\n",
    "    autocast_ctx = torch.autocast(device_type=\"mps\", dtype=torch.float16)\n",
    "    scaler = None  # MPS 无需 GradScaler\n",
    "elif device == \"cuda\":\n",
    "    from torch.cuda.amp import autocast as cuda_autocast, GradScaler\n",
    "    autocast_ctx = cuda_autocast(dtype=torch.float16)\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    autocast_ctx = nullcontext()\n",
    "    scaler = None\n",
    "\n",
    "# ============================================================\n",
    "# 5+. 评估函数（计算平均损失和准确率）\n",
    "# ============================================================\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            # 可选 channels_last：仅在非 CPU 且启用时转换\n",
    "            if USE_CHANNELS_LAST and device != \"cpu\":\n",
    "                x = x.to(device, memory_format=torch.channels_last, non_blocking=pin)\n",
    "            else:\n",
    "                x = x.to(device, non_blocking=pin)\n",
    "            y = y.to(device, non_blocking=pin)\n",
    "\n",
    "            with autocast_ctx:\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "            total_loss += float(loss.item()) * x.size(0)\n",
    "            total_acc  += (logits.argmax(1) == y).float().sum().item()\n",
    "            n += x.size(0)\n",
    "    return total_loss / n, total_acc / n\n",
    "\n",
    "# ============================================================\n",
    "# 6. 训练循环\n",
    "# ============================================================\n",
    "epochs = 3  # 为了快速演示只跑 3 个 epoch，可自行调大\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss, running_acc, total = 0.0, 0.0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # 可选 channels_last：仅在非 CPU 且启用时转换\n",
    "        if USE_CHANNELS_LAST and device != \"cpu\":\n",
    "            images = images.to(device, memory_format=torch.channels_last, non_blocking=pin)\n",
    "        else:\n",
    "            images = images.to(device, non_blocking=pin)\n",
    "        labels = labels.to(device, non_blocking=pin)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # 前向 + 计算 loss（半精度）\n",
    "        with autocast_ctx:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播与参数更新（CUDA 用 GradScaler，MPS/CPU 直接 backward）\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 统计训练准确率与损失\n",
    "        running_loss += float(loss.item()) * images.size(0)\n",
    "        running_acc  += (outputs.argmax(1) == labels).float().sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc  = running_acc / total\n",
    "    val_loss, val_acc = evaluate(test_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} | \"\n",
    "          f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
    "          f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. 可选：解冻部分卷积层进一步精调\n",
    "# ============================================================\n",
    "# 常见策略：先冻结特征层，稳定分类器；再解冻后几层继续训练（效果更好）\n",
    "# for param in model.features[6:].parameters():\n",
    "#     param.requires_grad = True\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "# 再跑若干 epoch ...\n",
    "\n",
    "# ============================================================\n",
    "# 8. 保存模型权重\n",
    "# ============================================================\n",
    "save_path = \"alexnet_cifar10_finetuned.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"✅ 模型已保存到 {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0acd6f5-86fe-41bf-ba3f-c9eb28579d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
