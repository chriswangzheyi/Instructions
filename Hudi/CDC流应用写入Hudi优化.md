# CDC流应用写入Hudi优化

大家如果在跑数百张表的数据CDC到Hudi。

你会惊奇地发现，这跟跑几张表的DEMO完全不是一码事。

就是特别的慢。并行度特别高的情况，HDFS的负载也是特别得高。

上百张表如果不去优化，想要跑出来一个不过的效果，轻轻松松吃掉集群几个TB的资源。

所以，我需要来跟大家聊聊我在设计流程序过程中给应用做的优化。

## 不做cache，自取灭亡

我们都知道Spark是基于DAG来进行stage调度，然后在基于TaskSceduler调度一个个任务的。

因为我们需要对CDC日志进行解析、验证以及转换处理。

所以，每一次计算都有可能会导致从源头重新拉取数据。

我们的CDC程序中要刷入上百张Hudi表，兄弟如果你没有做cache，这意味着：

**Streaming程序需要从Kafka重复拉取上百次数据**

如果有上千张表就更恐怖了。

大家可以自己去测试一下，在落地到表之前，不做cache的后果。

Kafka的topic中的数据是很大的，单个topic几十亿、上百亿的消息是正常水平。

大家可能会说，没事啊。

Kafka的吞吐超级高，

但考虑以下，吞吐再高，也经不住这样重复消费数据。

而且Kafka的吞吐会受到服务器IO的影响。

如果Kafka没有做限流，

一旦Kafka负载过高，导致其他的系统也无法正常生产、消费Kafka的数据。

**一次计算，扫描数百GB的缓存**

开启了Structured Streaming的cache后，

然后我们发现Kafka的负载下降了很多。


然后，发现每次刷入数据到Hudi时，光读取数据就要几分钟。

看了一下DAG，

确实不再从Kafka直接拉数据，

而是从cache中拉取数据，

这个cache也不小呢，每次Batch cache几十GB、上百GB。

每次对表做一次计算，都需要从扫描整个cache。

那么有几百表，

这个cache就需要被扫描几百次，

我需要让每个表后续的计算尽量读取少一些数据。

所以，我在基于batch的cache的基础之上。

再次做了一个针对表的二级缓存。

后续针对表的操作，直接拉取到的二级缓存就之拉取自己的数据即可。

### **总结下

一级缓存，就是Structured Streaming一个batch的cache，包含了所有表的cdc日志。一级缓存要解决的是Kafka重复消费问题。

二级缓存，Hudi表缓存。针对每个表，都会单独做一个cache，避免每个针对表的操作都需要重新读取一次一级缓存，从而提升读取效率。


## 单线程调度，就等着Kafka丢数吧

随着刷入的表越来越多，

发现Structured Streaming写入Hudi越来越慢。

而且你发现，Spark的任务并发没有利用好。

明明有几百个container，

并行的任务却只有几十个。

一个个的表地写。

所以，根据实践，

我们可以判断在foreachBatch中，Spark是单线程调度。

我们有几百张表需要刷入到Hudi中。

一个个表刷显然太不现实了。

刷入的数据太慢，

Kafka进数非常快，这就会导致，当我们正在消费某个数据。

Kafka积压的数据太多了，

所以触发了清理操作。

然后数据还没有被数据就丢掉了。

所以，根据实践，

我们需要自己来实现多线程调度，

你会用到Java的并发包，

然后一次将数据刷入若干个Hudi表中。

至少，一次启用几十个线程来刷Hudi表是没有问题的。


## 不要让所有表都写放大

在开发环境，调通了一个表的CDC日志解析后。

看见 Structured Streaming 能够即时将数据正确地刷入到Hudi。

天哪！历经困难重重，终于把数据刷到湖仓里面。

打开Spark SQL的cli，数据也能够正确的查询查询出来，统一hoodie_record_key对应的数据也能正确更新。

所以，我高兴地将Maven Profile切换到prod。

准备到准生产做一个验证。

几分钟地等待，

Maven把所有的shell、python、配置文件打包到了一个tar.gz。

废了九牛二虎之力，

将tar.gz包上传到准生产。

将要刷入LakeHouse的目标表元数据初始化好。

模拟上线大概几百张目标表。

当YARN把Streaming应用拉起来的时候，

我就发现有点不妙。

这些个表，

跑一次batch发现Web UI就展示了上千万个Stage。

准生产的HDFS集群负载一下飚满。

您猜怎么招？

Hudi要处理小文件，

就需要检查HDFS上的文件，

并且将小文件合并。

是不是感觉似曾相识？

我肯定你在Kudu、HBase等LSM结构的Compaction中见过。

写放大。

是不是慢点就慢点？

大不了数据就延迟大点。

不！

这样的写放大，

HDFS负载会猛增，

其他的任务还要不要玩？

还有，你确定Kafka会一直保存那些被积压的数据吗？

Log Compaction和Log Deletion会是摆设？

所以，这程序如果这样，

熬不了一天，在半夜业务库刷数的时候，就会直接因为Kafka数据丢失导致应用退出。

神马？

不退？

任何人都无法保证最终的数据是正确的。

耶稣都保不住，我说的。

你说：是不是该去调Spark、Hudi参数了？

大可以去试试，

在资源有限的情况下，

有很大可能会无功而返。

我问个问题：业务库的表中是不是每个表无时无刻都在刷数？

我想，95%的业务系统不会。

业务库中一定会有一些表是缓慢变化的。

而针对缓慢变化的业务表，根本没有必要每个Batch都去检查小文件、合并。

所以，每当在将数据刷入目标表之前。请一定要检查，当前这个Batch中有哪些目标表需要刷数。

