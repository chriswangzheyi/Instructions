# Spark 并行度怎么设置

## 规则

每个core承载2-4个partition比较合适

如果有32个core，那么就是64-128之间的并行度，也就是设置64-·18个partition

并行度和数据规模无关，只和内存和cpu有关。