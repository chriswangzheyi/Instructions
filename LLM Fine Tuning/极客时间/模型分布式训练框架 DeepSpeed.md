# æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ DeepSpeed



## ä¸€ã€DeepSpeed æ˜¯ä»€ä¹ˆ

**DeepSpeed** æ˜¯å¾®è½¯å¼€æºçš„ä¸€ä¸ªæ·±åº¦å­¦ä¹ è®­ç»ƒä¼˜åŒ–æ¡†æ¶ï¼Œä¸“é—¨ä¸º *ç™¾äº¿ï½ä¸‡äº¿å‚æ•°æ¨¡å‹* è®¾è®¡ã€‚
 å®ƒçš„ç›®æ ‡æ˜¯â€”â€”**è®©å¤§æ¨¡å‹åœ¨æœ‰é™æ˜¾å­˜ä¸Šä¹Ÿèƒ½è®­ç»ƒèµ·æ¥**ã€‚



æ ¸å¿ƒç»„ä»¶åŒ…æ‹¬ï¼š

| æ¨¡å—                                  | åŠŸèƒ½                                           |
| ------------------------------------- | ---------------------------------------------- |
| **ZeRO**                              | æ ¸å¿ƒä¼˜åŒ–å™¨ï¼Œåˆ†é˜¶æ®µå‡å°‘æ˜¾å­˜å ç”¨                 |
| **æ¨¡å‹å¹¶è¡Œ (Model Parallelism)**      | æŠŠæ¨¡å‹å±‚æ‹†åˆ†åˆ°ä¸åŒGPU                          |
| **æµæ°´çº¿å¹¶è¡Œ (Pipeline Parallelism)** | æŠŠå‰å‘/åå‘ä¼ æ’­åˆ†é˜¶æ®µå¹¶è¡Œ                      |
| **ç¨€ç–æ³¨æ„åŠ› (Sparse Attention)**     | é™ä½Transformerè®¡ç®—å¤æ‚åº¦                      |
| **Offload/Infinity**                  | æŠŠéƒ¨åˆ†æ•°æ®å¸è½½åˆ° CPU æˆ– NVMe ç¡¬ç›˜ï¼ŒèŠ‚çœGPUæ˜¾å­˜ |



## äºŒã€ZeRO (Zero Redundancy Optimizer)

æ™®é€šçš„åˆ†å¸ƒå¼è®­ç»ƒé‡Œï¼Œæ¯ä¸ªGPUéƒ½ä¼šå­˜ä¸€æ•´ä»½æ¨¡å‹å‰¯æœ¬ âœ æ˜¾å­˜æµªè´¹ã€‚
 **ZeRO çš„åˆ›æ–°ç‚¹**æ˜¯ï¼š**æŠŠå‚æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€éƒ½åˆ†ç‰‡åˆ†å¸ƒåœ¨ä¸åŒGPU**ï¼Œè®©æ˜¾å­˜åˆ©ç”¨ç‡å¤§å¹…æå‡ã€‚



##### ğŸ”¹ ä¸‰ä¸ªé˜¶æ®µï¼ˆä»¥ Adam ä¼˜åŒ–å™¨ä¸ºä¾‹ï¼‰ï¼š

| é˜¶æ®µ        | åˆ†ç‰‡å†…å®¹                        | æ˜¾å­˜å‹ç¼©   | é€šä¿¡ä»£ä»·  |
| ----------- | ------------------------------- | ---------- | --------- |
| **Stage 1** | ä¼˜åŒ–å™¨çŠ¶æ€ (momentum, variance) | 4 Ã—        | æ— å˜åŒ–    |
| **Stage 2** | å†åŠ ä¸Šæ¢¯åº¦åˆ†ç‰‡                  | 8 Ã—        | æ— å˜åŒ–    |
| **Stage 3** | è¿æ¨¡å‹å‚æ•°ä¹Ÿåˆ†ç‰‡                | GPU æ•°å€æ•° | â†‘ çº¦ 50 % |



ğŸ‘‰ ä¸¾ä¾‹ï¼š
 LLaMA-2 7B æ¨¡å‹æŒ‰ bf16 è®­ç»ƒéœ€è¦ çº¦ 120 GB æ˜¾å­˜ï¼Œ
 ä½† ZeRO-3 åœ¨ 64 å¼  GPU ä¸Šå¯å®ç° 64 å€æ˜¾å­˜å‹ç¼©ã€‚





## ä¸‰ã€è¿›ä¸€æ­¥ä¼˜åŒ–ï¼šZeRO-Rã€Offloadã€Infinity

| æ¨¡å—                  | ä¸»è¦æ€è·¯                                                     |
| --------------------- | ------------------------------------------------------------ |
| **ZeRO-R (Residual)** | è§£å†³å†…å­˜ç¢ç‰‡åŒ–å’Œæ¿€æ´»å†—ä½™é—®é¢˜ï¼ŒåŒ…å«åˆ†åŒºæ¿€æ´»æ£€æŸ¥ç‚¹ã€æ’å®šç¼“å†²åŒºã€å†…å­˜æ•´ç†ä¸‰é¡¹æŠ€æœ¯ |
| **ZeRO-Offload**      | æŠŠä¼˜åŒ–å™¨çŠ¶æ€æˆ–æ¢¯åº¦**å¸è½½åˆ° CPU å†…å­˜**ï¼›éƒ¨åˆ†è®¡ç®—ä¹Ÿè½¬ç§»åˆ° CPU** |
| **ZeRO-Infinity**     | ç»“åˆ CPU + NVMe å¤šå±‚å­˜å‚¨ï¼Œä½¿æ¨¡å‹è§„æ¨¡å¯æ‰©å±•åˆ°**ç™¾ä¸‡äº¿å‚æ•°**ï¼ŒGPU ä»…è´Ÿè´£å‰åå‘è®¡ç®— |





## å››ã€DeepSpeed åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„è§’è‰²

| å¹¶è¡Œæ–¹å¼            | è¯´æ˜                                         |
| ------------------- | -------------------------------------------- |
| **æ•°æ®å¹¶è¡Œ (DP)**   | ä¸åŒGPU è®­ç»ƒä¸åŒæ•°æ®æ‰¹æ¬¡ï¼Œå‚æ•°æ¢¯åº¦åŒæ­¥       |
| **æ¨¡å‹å¹¶è¡Œ (MP)**   | æ¨¡å‹å±‚åˆ‡ç‰‡åˆ°ä¸åŒGPU                          |
| **æµæ°´çº¿å¹¶è¡Œ (PP)** | å‰åå‘ä¼ æ’­åˆ†é˜¶æ®µå¹¶è¡Œæ‰§è¡Œ                     |
| **æ··åˆå¹¶è¡Œ**        | DP + MP + PP + ZeRO ç»“åˆä½¿ç”¨ï¼Œæ”¯æŒä¸‡äº¿çº§æ¨¡å‹ |

DeepSpeed çš„ ZeRO ç³»åˆ—æœ¬è´¨ä¸Šæ˜¯æŠŠ**æ•°æ®å¹¶è¡Œå‡çº§æˆâ€œé›¶å†—ä½™æ•°æ®å¹¶è¡Œâ€**ã€‚





## äº”ã€ä¸ Transformers é›†æˆä½¿ç”¨

Hugging Face çš„ `Trainer` æ”¯æŒç›´æ¥æ¥å…¥ DeepSpeedï¼Œåªéœ€é…ç½®å‚æ•°ï¼š

```
python train.py \
  --model_name_or_path t5-large \
  --deepspeed ds_config_zero2.json \
  --do_train --do_eval
```

æˆ–è€…é€šè¿‡ `HfDeepSpeedConfig` ä¼ å…¥é…ç½®æ–‡ä»¶ï¼Œå°±èƒ½è‡ªåŠ¨è°ƒç”¨ DeepSpeed ä¼˜åŒ–



## å…­ã€é…ç½®ç¤ºä¾‹ï¼ˆZeRO-2 & ZeRO-3ï¼‰

| é…ç½®       | ç‰¹ç‚¹                                              |
| ---------- | ------------------------------------------------- |
| **ZeRO-2** | æ˜¾å­˜èŠ‚çœçº¦ 8 å€ï¼›è®­ç»ƒé€Ÿåº¦å¿«                       |
| **ZeRO-3** | æ˜¾å­˜å‹ç¼©æ›´å¼ºï¼Œå¯ CPU å¸è½½ï¼›è®­ç»ƒè¾ƒæ…¢ä½†èƒ½è£…æ›´å¤§æ¨¡å‹ |



## ä¸ƒã€å•æœºå¤šå¡ä¸åˆ†å¸ƒå¼è®­ç»ƒå‘½ä»¤

#### âœ… å•æœºå¤šå¡ï¼š

```
deepspeed --num_gpus=4 your_program.py --deepspeed ds_config_zero2.json
```

#### âœ… å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼ï¼š

```
deepspeed --num_gpus 8 --num_nodes 2 --hostfile hostfile \
your_program.py --deepspeed ds_config_zero3.json
```

`hostfile` å®šä¹‰å„èŠ‚ç‚¹ GPU æ•°é‡ä¸åœ°å€ã€‚
 DeepSpeed ä¹Ÿæ”¯æŒ SLURM é›†ç¾¤ç®¡ç†æ¨¡å¼ã€‚



## å…«ã€æ€»ç»“ï¼šDeepSpeed çš„æ ¸å¿ƒä¼˜åŠ¿

- ğŸš€ **æ˜¾å­˜èŠ‚çœ** ï¼šåˆ†ç‰‡å­˜å‚¨ + Offload æŠ€æœ¯ï¼Œèƒ½åœ¨å°æ˜¾å­˜å¡ä¸Šè®­å¤§æ¨¡å‹
- ğŸ§© **æ¨¡å—åŒ–** ï¼šæ”¯æŒ Transformerã€MoEã€RLHF ç­‰å¤šç§è®­ç»ƒèŒƒå¼
- âš™ï¸ **æ˜“é›†æˆ** ï¼šä¸ Transformers æ— ç¼ç»“åˆ
- ğŸ“ˆ **é«˜æ‰©å±•æ€§** ï¼šæ”¯æŒ GPU â†’ CPU â†’ NVMe çš„å¤šå±‚åˆ†å¸ƒå¼è®­ç»ƒ





## ä¹ã€é€šä¿—è§£é‡Š



##### å…ˆç†è§£é—®é¢˜ï¼šä¸ºä»€ä¹ˆæ™®é€šè®­ç»ƒæµªè´¹æ˜¾å­˜

æƒ³è±¡ä½ æœ‰ 4 ä¸ªåŒå­¦ï¼ˆGPUï¼‰ï¼Œè¦ä¸€èµ·èƒŒä¸€æœ¬ 400 é¡µçš„ä¹¦ï¼ˆæ¨¡å‹å‚æ•°ï¼‰ã€‚

#### **(1)æ™®é€šåšæ³•ï¼ˆData Parallelï¼‰**ï¼š

 æ¯ä¸ªäººéƒ½å„è‡ªèƒŒå®Œæ•´ 400 é¡µï¼Œæ¯äººå ç”¨åŒæ ·çš„å†…å­˜ç©ºé—´ã€‚

```
GPU1: 400 é¡µ
GPU2: 400 é¡µ
GPU3: 400 é¡µ
GPU4: 400 é¡µ
```

â¡ï¸ è¿™æ ·ä¸€æ¥ï¼Œ**4 å° GPU ç”¨äº† 1600 é¡µçš„å†…å­˜ç©ºé—´ï¼Œå´åªå¹²äº†ä¸€æœ¬ä¹¦çš„äº‹ã€‚**

è¿™å°±æ˜¯ä¼ ç»Ÿæ•°æ®å¹¶è¡Œçš„æµªè´¹ï¼š

- æ¯å¼  GPU å­˜ç€ä¸€æ ·çš„æ¨¡å‹å‚æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€‚
- ä½†æ¯æ¬¡åå‘ä¼ æ’­åªç”¨åˆ°è‡ªå·±é‚£ä¸€éƒ¨åˆ†æ ·æœ¬ã€‚

------



#### (2) ZeROï¼šå¤§å®¶ã€Œåˆ†å·¥èƒŒä¹¦ã€ï¼

ZeRO çš„æ ¸å¿ƒæ€æƒ³å°±æ˜¯ï¼š

> æ—¢ç„¶å¤§å®¶ç®—çš„æ˜¯ä¸åŒçš„æ ·æœ¬ï¼Œä¸ºä»€ä¹ˆä¸ **æŠŠæ¨¡å‹å†…å®¹æ‹†å¼€æ¥åˆ†ç€å­˜å‘¢ï¼Ÿ**

ğŸ¯ æ ¸å¿ƒç‚¹ï¼šæŠŠå¤§æ¨¡å‹â€œåˆ‡ç‰‡â€åˆ†å¸ƒåˆ°ä¸åŒ GPU ä¸Šã€‚

------

#### (3)ZeRO å„é˜¶æ®µé€šä¿—è§£é‡Š

##### ğŸ¥‡ Stage 1ï¼šåªåˆ†ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆOptimizer Statesï¼‰

ä¼˜åŒ–å™¨çŠ¶æ€æŒ‡ Adam çš„åŠ¨é‡é¡¹ `m`ã€æ–¹å·®é¡¹ `v` ç­‰ã€‚
 å®ƒä»¬å æ˜¾å­˜æœ€å¤šï¼ˆå¾€å¾€æ˜¯æ¨¡å‹å‚æ•°çš„ 2 å€ï¼‰ã€‚

Stage 1 å°±æ˜¯è®©ï¼š

- GPU1 å­˜ç¬¬ä¸€éƒ¨åˆ† `m`/`v`
- GPU2 å­˜ç¬¬äºŒéƒ¨åˆ† â€¦
- GPU3 å­˜ç¬¬ä¸‰éƒ¨åˆ† â€¦

æ¯ä¸ª GPU **åªä¿å­˜éƒ¨åˆ†çŠ¶æ€**ï¼Œå‡å°‘å†—ä½™ã€‚

ğŸ§  ç±»æ¯”ï¼š

> ä»¥å‰æ¯ä¸ªäººéƒ½å¸¦ç€æ•´æœ¬ã€Šè¯æ±‡æ‰‹å†Œã€‹ï¼ˆä¼˜åŒ–å™¨çŠ¶æ€ï¼‰èƒŒå•è¯ï¼›
>  ç°åœ¨æ¯ä¸ªäººåªèƒŒè‡ªå·±è´Ÿè´£çš„ 1/4ï¼Œæœ¬å­è½»äº†å››å€ï¼

------

##### ğŸ¥ˆ Stage 2ï¼šå†æŠŠã€Œæ¢¯åº¦ã€ä¹Ÿåˆ†å¼€

åå‘ä¼ æ’­åæ¯ä¸ª GPU éƒ½ç®—å‡ºæ¢¯åº¦ dWã€‚
 ä»¥å‰æ¯å° GPU éƒ½ä¿ç•™å®Œæ•´æ¢¯åº¦ï¼›
 ç°åœ¨åªä¿ç•™è‡ªå·±è´Ÿè´£é‚£ä¸€éƒ¨åˆ†ã€‚

ğŸ§  ç±»æ¯”ï¼š

> æ¯ä¸ªäººä¸ä»…å„è‡ªèƒŒäº†ä¸åŒé¡µçš„è¯æ±‡è¡¨ï¼ˆä¼˜åŒ–å™¨çŠ¶æ€ï¼‰ï¼Œ
>  è¿å¤ä¹ ç¬”è®°ï¼ˆæ¢¯åº¦ï¼‰ä¹Ÿåˆ†å¼€è®°ã€‚

------

##### ğŸ¥‰ Stage 3ï¼šè¿ã€Œæ¨¡å‹å‚æ•°ã€ä¹Ÿåˆ†å¼€ï¼

Stage 3 æ˜¯æœ€å½»åº•çš„ï¼š

- å‚æ•°ï¼ˆweightsï¼‰
- æ¢¯åº¦ï¼ˆgradientsï¼‰
- ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆoptimizer statesï¼‰
   éƒ½åˆ†å¸ƒå¼åˆ‡ç‰‡ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯å¼  GPU åªå­˜**æ¨¡å‹çš„ä¸€éƒ¨åˆ†**å‚æ•°ã€‚
 å½“è®­ç»ƒéœ€è¦ç”¨åˆ°å®Œæ•´å‚æ•°æ—¶ï¼Œé€šè¿‡ç½‘ç»œæš‚æ—¶èšåˆï¼ˆé€šä¿¡ï¼‰ï¼Œ
 è®¡ç®—å®Œå†é‡Šæ”¾ã€‚

ğŸ§  ç±»æ¯”ï¼š

> ä»¥å‰ 4 ä¸ªäººéƒ½èƒŒ 400 é¡µçš„å…¨ä¹¦ï¼›
>  ç°åœ¨æ¯äººåªèƒŒ 100 é¡µï¼Œéœ€è¦æ•´æœ¬æ—¶å¤§å®¶åˆåœ¨ä¸€èµ·å¿µä¸€éã€‚
>  æ˜¾å­˜ç¬é—´å‡ 75%ï¼

------

#### ğŸ’¡(4)ä¸ºä»€ä¹ˆæ˜¾å­˜èƒ½çœè¿™ä¹ˆå¤šï¼Ÿ

ä¸¾ä¸ª GPT-3 è®­ç»ƒä¾‹å­ï¼š

- æ¨¡å‹å‚æ•°ï¼š1750 äº¿
- æ¯ä¸ªå‚æ•° 2 å­—èŠ‚ï¼ˆFP16ï¼‰â‰ˆ 350 GB
- ä¼˜åŒ–å™¨çŠ¶æ€ + æ¢¯åº¦å…±çº¦ 3 å€
   â¡ï¸ ä¸€å…±éœ€è¦çº¦ 1.2 TB æ˜¾å­˜ã€‚

ä½¿ç”¨ ZeROï¼š

- Stage 1ï¼šé™åˆ°çº¦ 300 GB
- Stage 2ï¼šé™åˆ°çº¦ 150 GB
- Stage 3ï¼šé™åˆ°çº¦ 50 GBï¼ˆ4 å¼  GPU æ—¶ï¼‰

æ‰€ä»¥ ZeRO çš„æ ¸å¿ƒè´¡çŒ®å°±æ˜¯ï¼š

> ğŸ’¾ **è®©åŸæœ¬æ— æ³•è£…è¿› GPU çš„å¤§æ¨¡å‹ï¼Œå¯ä»¥è¢«â€œåˆ†ç‰‡æ‹¼è£…â€èµ·æ¥è®­ç»ƒã€‚**

------

#### ğŸ” (5)ã€Stage 3 å·¥ä½œåŸç†ï¼ˆå›¾ç¤ºæ€è·¯ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å‚æ•°åˆ‡ç‰‡  â†“       é€šä¿¡èšåˆ  â†‘       å‚æ•°åˆ‡ç‰‡  â†“   â”‚
â”‚                                                    â”‚
â”‚  GPU1   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  GPU1           â”‚
â”‚  GPU2   â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€  GPU2           â”‚
â”‚  GPU3   â”€â”€â”€â”€â”  â”‚ â”‚    â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€  GPU3           â”‚
â”‚  GPU4   â”€â”  â”‚  â”‚ â”‚    â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€  GPU4           â”‚
â”‚        forward/backward  â†â†’  gather/scatter å‚æ•° â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

------

#### âœ… (6)ã€æ€»ç»“ä¸€å¥è¯

| é˜¶æ®µ   | åŸç†           | ç±»æ¯”         | æ˜¾å­˜èŠ‚çœ |
| ------ | -------------- | ------------ | -------- |
| ZeRO-1 | åˆ†ç‰‡ä¼˜åŒ–å™¨çŠ¶æ€ | å…±äº«è¯æ±‡æ‰‹å†Œ | çº¦ 4Ã—    |
| ZeRO-2 | åŠ ä¸Šåˆ†ç‰‡æ¢¯åº¦   | è¿ç¬”è®°ä¹Ÿåˆ†å¼€ | çº¦ 8Ã—    |
| ZeRO-3 | è¿å‚æ•°éƒ½åˆ†ç‰‡   | æ¯äººèƒŒä¸åŒé¡µ | GPU æ•°å€ |



## Demo



```python
# -*- coding: utf-8 -*-
"""
ZeRO æ˜¾å­˜èŠ‚çœæ¼”ç¤ºä»£ç ï¼ˆå¸¦æ˜¾å­˜ç»Ÿè®¡ï¼‰
é€‚åˆåœ¨ Colab / æœ¬åœ° GPU ç¯å¢ƒä¸­è¿è¡Œ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import gc

torch.manual_seed(42)
torch.cuda.empty_cache()

# æ¨¡æ‹Ÿä¸€ä¸ªè¾ƒå¤§çš„å…¨è¿æ¥æ¨¡å‹
class BigModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(4096, 4096)
        self.fc2 = nn.Linear(4096, 4096)

    def forward(self, x):
        return self.fc2(torch.relu(self.fc1(x)))


def print_mem(tag, device):
    if device.type == "cuda":
        mem = torch.cuda.memory_allocated(device) / 1024**2
    elif device.type == "mps":
        mem = torch.mps.current_allocated_memory() / 1024**2
    else:
        mem = 0
    print(f"[{tag}] å½“å‰æ˜¾å­˜å ç”¨: {mem:.2f} MB (device={device})")


# æ™®é€šè®­ç»ƒï¼ˆæ—  ZeROï¼‰
def normal_train_step(device):
    model = BigModel().to(device)
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    x = torch.randn(8, 4096).to(device)
    y = torch.randn(8, 4096).to(device)

    out = model(x)
    loss = (out - y).pow(2).mean()
    loss.backward()
    optimizer.step()
    print_mem("æ™®é€šè®­ç»ƒ", device)
    del model, optimizer, x, y
    gc.collect()
    torch.cuda.empty_cache()


# æ¨¡æ‹Ÿ ZeRO å„é˜¶æ®µ
def zero_stage(stage):
    total_params = sum(p.numel() for p in BigModel().parameters())
    gpu_count = 4
    base_mem = total_params * 4 / 1024**2  # 4 bytes per param (FP32)
    if stage == 1:
        mem = base_mem / 4 * 3  # å‚æ•°+æ¢¯åº¦ä¸å˜ï¼Œä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡
    elif stage == 2:
        mem = base_mem / 4 * 2  # ä¼˜åŒ–å™¨çŠ¶æ€+æ¢¯åº¦åˆ†ç‰‡
    elif stage == 3:
        mem = base_mem / 4      # å‚æ•°+æ¢¯åº¦+ä¼˜åŒ–å™¨çŠ¶æ€å…¨åˆ†ç‰‡
    print(f"ğŸ§© ZeRO Stage {stage} ç†è®ºæ˜¾å­˜å ç”¨: {mem:.2f} MB (ç›¸å¯¹æ™®é€šè®­ç»ƒçº¦èŠ‚çœ {4-stage+1}Ã—)")


# =========================================================
# æ¼”ç¤ºæ‰§è¡Œ
# =========================================================
print("=== æ˜¾å­˜å¯¹æ¯”æ¼”ç¤º ===\n")

# æ™®é€šè®­ç»ƒ
device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
normal_train_step(device)

# æ¨¡æ‹Ÿ ZeRO Stage 1 / 2 / 3
for s in [1, 2, 3]:
    zero_stage(s)

print("\nâœ… æç¤ºï¼šå®é™… DeepSpeed ZeRO-3 ä¼šåŠ¨æ€ gather å‚æ•°å‚ä¸å‰å‘/åå‘ï¼Œå† scatter å›å„ GPUã€‚")

```

### æ‰“å°

```
=== æ˜¾å­˜å¯¹æ¯”æ¼”ç¤º ===

[æ™®é€šè®­ç»ƒ] å½“å‰æ˜¾å­˜å ç”¨: 513.16 MB (device=mps)
ğŸ§© ZeRO Stage 1 ç†è®ºæ˜¾å­˜å ç”¨: 96.02 MB (ç›¸å¯¹æ™®é€šè®­ç»ƒçº¦èŠ‚çœ 4Ã—)
ğŸ§© ZeRO Stage 2 ç†è®ºæ˜¾å­˜å ç”¨: 64.02 MB (ç›¸å¯¹æ™®é€šè®­ç»ƒçº¦èŠ‚çœ 3Ã—)
ğŸ§© ZeRO Stage 3 ç†è®ºæ˜¾å­˜å ç”¨: 32.01 MB (ç›¸å¯¹æ™®é€šè®­ç»ƒçº¦èŠ‚çœ 2Ã—)

âœ… æç¤ºï¼šå®é™… DeepSpeed ZeRO-3 ä¼šåŠ¨æ€ gather å‚æ•°å‚ä¸å‰å‘/åå‘ï¼Œå† scatter å›å„ GPUã€‚
```

