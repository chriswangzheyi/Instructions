# 分布式训练框架选择?



## 什么是分布式训练

分布式训练（Distributed Training）指的是把模型训练任务分散到多个 GPU 或机器上同时执行，以加快训练速度、扩大模型规模或突破单机显存限制。它的核心思想是：**并行化计算与同步参数更新**。



分布式训练主要分为三种模式：

1. **数据并行（Data Parallel）**：每张 GPU 处理不同的训练样本副本，计算梯度后做同步（最常见）。
2. **模型并行（Model Parallel）**：把模型的不同部分放在不同 GPU 上，解决大模型放不下显存的问题。
3. **流水线并行（Pipeline Parallel）**：将模型拆成若干阶段，前一阶段的输出作为后一阶段的输入，可以提高设备利用率。



## 主流框架对比与选型逻辑



| 框架                                           | 特点                         | 优点                                   | 典型场景             |
| ---------------------------------------------- | ---------------------------- | -------------------------------------- | -------------------- |
| **PyTorch DDP (DistributedDataParallel)**      | 原生官方实现，数据并行       | 简单、稳定、生态完善                   | 小中型模型，多卡训练 |
| **PyTorch FSDP (Fully Sharded Data Parallel)** | 参数、梯度、优化器都分片     | 显存占用少，支持更大模型               | 7B–30B 级别模型      |
| **DeepSpeed (ZeRO-1/2/3)**                     | 微软开源，显存极限优化       | 支持 CPU/NVMe Offload，多并行维度      | 超大模型、显存吃紧   |
| **Megatron-LM / Megatron-Core**                | 专为超大模型（30B+）         | 支持 Tensor + Pipeline + Data 三维并行 | 大模型预训练         |
| **Horovod**                                    | Uber 开源，支持多框架        | 可移植性强，易迁移到 TensorFlow        | 混合框架场景         |
| **Ray Train**                                  | 调度框架，支持弹性训练与容错 | 易集成 AutoML 与超参搜索               | 分布式任务编排       |



## 分布式训练中的通信与优化



### 通信后端

- **NCCL**（NVIDIA Collective Communication Library）：GPU 通信首选；
- **Gloo**：CPU 通信；
- **MPI**：传统集群通信方案。

### 通信优化技巧

1. **梯度累积（Gradient Accumulation）**：多次前向后再一次同步梯度；
2. **混合精度（AMP/BF16）**：减少显存占用、提高吞吐；
3. **通信重叠计算（Overlap Comm & Compute）**：异步通信提高利用率；
4. **拓扑感知（Topology-aware）**：利用 NVLink/NVSwitch 优化带宽。





## 分布式训练的关键技术点



| 技术                                 | 功能                         | 实现                             |
| ------------------------------------ | ---------------------------- | -------------------------------- |
| **Gradient Checkpointing**           | 节省激活内存（重算部分前向） | PyTorch `torch.utils.checkpoint` |
| **Activation Offload**               | 将激活暂存到 CPU / NVMe      | DeepSpeed Offload                |
| **Zero Redundancy Optimizer (ZeRO)** | 分片参数+梯度+优化器         | DeepSpeed ZeRO                   |
| **Mixed Precision (AMP)**            | 降低精度以提速               | `torch.cuda.amp`                 |
| **Elastic Training**                 | 动态扩缩容                   | TorchElastic / Ray Train         |



## 不同规模的最佳实践推荐



| 规模               | GPU 环境   | 推荐框架                      | 技术要点                   |
| ------------------ | ---------- | ----------------------------- | -------------------------- |
| 小规模（≤7B）      | 单机多卡   | DDP                           | AMP + Grad Accumulation    |
| 中等规模（7B–30B） | 多机多卡   | FSDP / ZeRO-2                 | Sharding + Checkpointing   |
| 大规模（30B–70B）  | 多机多节点 | ZeRO-3 / Megatron             | 3D 并行 + Offload          |
| 超大规模（100B+）  | 专用集群   | Megatron-Deepspeed / Colossal | 张量 + 流水 + 数据并行结合 |

