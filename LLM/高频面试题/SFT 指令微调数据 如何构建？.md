# **SFT** 指令微调数据 如何构建？



## **SFT** 指令微调数据 如何构建？



SFT 的目的是让模型：

> 从「能说话」变成「听得懂指令 + 会按人类逻辑回答」。

因此数据集的本质是：

> 一组 **「指令（Instruction）」+「期望回答（Response）」** 样本对，
>  模型通过模仿这些示例，学习“人类任务的表达方式”。



## 数据基本结构（标准格式）



一个 SFT 样本通常长这样 👇

```python
{
  "instruction": "请解释牛顿第三定律。",
  "input": "",
  "output": "牛顿第三定律表明：作用力与反作用力大小相等、方向相反。"
}

```

带上下文输入的例子：

```python
{
  "instruction": "请根据以下段落写出一段总结。",
  "input": "人工智能（AI）是一种通过计算机模拟人类智能行为的技术……",
  "output": "人工智能是一种使计算机具备学习和推理能力的技术，用于处理复杂任务。"
}

```



## 构建 SFT 数据集的 5 个步骤

| 阶段                       | 目标                     | 说明                                                         |
| -------------------------- | ------------------------ | ------------------------------------------------------------ |
| **1️⃣ 确定任务范围**         | 明确模型的“用途”         | 如通用问答、旅游客服、代码助手、法条解释等                   |
| **2️⃣ 收集原始语料**         | 获取指令来源             | 来自开源集（如 Alpaca、Dolly、ShareGPT）、自建问答对、专业文档等 |
| **3️⃣ 指令生成 / 清洗**      | 让指令自然多样           | 可用 GPT 帮你生成 paraphrase 的任务描述                      |
| **4️⃣ 答案构造（Response）** | 给每条指令生成高质量答案 | 可人工标注、AI 辅助（GPT-4/Claude等）或混合方式              |
| **5️⃣ 质量过滤与格式化**     | 清洗低质、冗余样本       | 去重、检测毒性、语法、长度、token限制等                      |





## SFT 数据构建的三种来源方式

| 来源方式                        | 描述                                | 优点             | 缺点                 |
| ------------------------------- | ----------------------------------- | ---------------- | -------------------- |
| **人工标注（Human Annotated）** | 专家或标注员撰写问题和答案          | 精度高，可控性强 | 成本高、产量低       |
| **AI 生成（Synthetic Data）**   | 用 GPT-4 等模型批量生成指令和回答   | 快速扩充、多样   | 质量需过滤、易模板化 |
| **混合生成（Human + AI）**      | 人设计任务框架，AI 生成内容，人复核 | 平衡质量与规模   | 成本适中             |





## 如何让数据“高质量”

### ✅ 1. 多样性（Diversity）

- 不要只出现“请解释”“请写一篇”“请总结”；
- 混合不同任务类型、表达方式、语气风格。

### ✅ 2. 真实性（Groundedness）

- 输出应基于事实或明确上下文；
- 避免幻想式（hallucination）回答。

### ✅ 3. 结构化（Structure）

- 明确段落、标题、项目符号、列表；
- 有助于模型学习格式生成。

### ✅ 4. 推理性（Reasoning）

- 设计包含逻辑链、计算、分析的问题；
- 如：“请解释你是如何得出这个结论的”。

### ✅ 5. 平衡性（Balance）

- 不要让模型过度学会“解释”或“拒答”；
- 应有问答、生成、分类、编辑、摘要等多类型任务。





## 常见任务类型模板



| 任务类型                       | 示例指令                                        | 输出特征      |
| ------------------------------ | ----------------------------------------------- | ------------- |
| **问答 (QA)**                  | “量子计算和传统计算的区别是什么？”              | 解释性文本    |
| **总结 (Summarization)**       | “请总结以下新闻的主要观点：…”                   | 摘要段落      |
| **改写 (Paraphrase)**          | “请将以下句子改写得更正式：…”                   | 改写后的文本  |
| **分类 (Classification)**      | “判断这条评论是积极还是消极：…”                 | 类别标签      |
| **翻译 (Translation)**         | “把这段文字翻译成英文：…”                       | 翻译文本      |
| **推理 (Reasoning)**           | “一个盒子里有3个红球和2个蓝球…求取红球的概率。” | 推理+计算步骤 |
| **代码任务 (Code)**            | “写一个Python函数实现冒泡排序。”                | 代码块        |
| **角色扮演 / 对话 (Roleplay)** | “你是一个旅行顾问，请推荐巴黎3日游行程。”       | 场景化回答    |



## 构建实操：自动化数据管线

可以使用类似流程自动生成和清洗：

```
数据源（开源+自建） 
→ 指令生成器（Prompt模板 + GPT-4）
→ 响应生成（多模型投票）
→ 质量过滤（重复、长度、毒性、语法）
→ 结构化格式化（JSONL）
→ Token统计 & 样本均衡
```

Python 工具链可用：

- `datasets`（HuggingFace）管理数据；
- `langchain`/`lighteval` 生成与清洗；
- `pandas` + `OpenAI API` 做自动过滤。



## 进阶技巧：让 SFT 数据“更聪明”

| 技巧                       | 说明                                            |
| -------------------------- | ----------------------------------------------- |
| **Self-Instruct 方法**     | 用大模型自生成任务数据（GPT-4生成指令、再自答） |
| **Multi-turn Dialogue**    | 构造多轮上下文问答，提高对话记忆能力            |
| **Chain-of-Thought (CoT)** | 在输出中显式展示推理过程                        |
| **Tool-Use 指令**          | 让模型学会调用外部API、计算器等                 |
| **Rewarded Filtering**     | 用奖励模型或人工评分筛选高分样本                |



## 推荐的开源数据集

| 数据集                          | 来源             | 特点                         |
| ------------------------------- | ---------------- | ---------------------------- |
| **Alpaca / ShareGPT**           | Stanford / 社区  | 最常见指令微调样本           |
| **Dolly 15k**                   | Databricks       | 人工标注、开放许可           |
| **OpenAssistant Conversations** | LAION            | 多轮对话、结构化标注         |
| **FLAN v2 / T0**                | Google           | 多任务混合（翻译、QA、逻辑） |
| **COIG (中文)**                 | 中文多领域指令集 | 中文高质量微调集             |
| **BELLE / Firefly / Guanaco**   | 中文 SFT 数据集  | 适合中文模型指令训练         |