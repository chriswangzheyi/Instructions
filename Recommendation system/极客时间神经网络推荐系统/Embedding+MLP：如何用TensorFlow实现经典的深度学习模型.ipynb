{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p1KCNa-iaWLz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "samples_file_path = \"modelSamples.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(file_path):\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_path,\n",
        "        batch_size=12,\n",
        "        label_name='label',\n",
        "        na_value=\"?\",\n",
        "        num_epochs=1,\n",
        "        ignore_errors=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "# sample dataset size 110830/12(batch_size) = 9235\n",
        "raw_samples_data = get_dataset(samples_file_path)\n",
        "\n",
        "\n",
        "test_dataset = raw_samples_data.take(1000)\n",
        "train_dataset = raw_samples_data.skip(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pkIQIN3a3OJ",
        "outputId": "e05907c0-eff2-4596-f853-e137880dd404"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/readers.py:573: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.ignore_errors` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_vocab = ['Film-Noir', 'Action', 'Adventure', 'Horror', 'Romance', 'War', 'Comedy', 'Western', 'Documentary',\n",
        "               'Sci-Fi', 'Drama', 'Thriller',\n",
        "               'Crime', 'Fantasy', 'Animation', 'IMAX', 'Mystery', 'Children', 'Musical']\n",
        "\n",
        "\n",
        "GENRE_FEATURES = {\n",
        "    'userGenre1': genre_vocab,\n",
        "    'userGenre2': genre_vocab,\n",
        "    'userGenre3': genre_vocab,\n",
        "    'userGenre4': genre_vocab,\n",
        "    'userGenre5': genre_vocab,\n",
        "    'movieGenre1': genre_vocab,\n",
        "    'movieGenre2': genre_vocab,\n",
        "    'movieGenre3': genre_vocab\n",
        "}\n",
        "\n",
        "\n",
        "categorical_columns = []\n",
        "for feature, vocab in GENRE_FEATURES.items():\n",
        "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "    emb_col = tf.feature_column.embedding_column(cat_col, 10)\n",
        "    categorical_columns.append(emb_col)\n",
        "\n",
        "\n",
        "movie_col = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1001)\n",
        "movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)\n",
        "categorical_columns.append(movie_emb_col)\n",
        "\n",
        "\n",
        "user_col = tf.feature_column.categorical_column_with_identity(key='userId', num_buckets=30001)\n",
        "user_emb_col = tf.feature_column.embedding_column(user_col, 10)\n",
        "categorical_columns.append(user_emb_col)"
      ],
      "metadata": {
        "id": "4Toz16aYbAM_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = [tf.feature_column.numeric_column('releaseYear'),\n",
        "                   tf.feature_column.numeric_column('movieRatingCount'),\n",
        "                     tf.feature_column.numeric_column('movieAvgRating'),\n",
        "                     tf.feature_column.numeric_column('movieRatingStddev'),\n",
        "                     tf.feature_column.numeric_column('userRatingCount'),\n",
        "                     tf.feature_column.numeric_column('userAvgRating'),\n",
        "                     tf.feature_column.numeric_column('userRatingStddev')]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBArryEXbBmm",
        "outputId": "9ac934e0-b84e-4691-b8b4-daa71496bae1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-e409df2b23d2>:1: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns)\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    preprocessing_layer,\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])"
      ],
      "metadata": {
        "id": "BcQokaKdbDCX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Jju7I69SbLOS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=10)\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYPkpUihbMWF",
        "outputId": "83768a81-5d62-4ef6-ccff-1a8c451efbb5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8232/8232 [==============================] - 153s 18ms/step - loss: 2.7467 - accuracy: 0.5805\n",
            "Epoch 2/10\n",
            "8232/8232 [==============================] - 145s 18ms/step - loss: 0.6289 - accuracy: 0.6711\n",
            "Epoch 3/10\n",
            "8232/8232 [==============================] - 145s 17ms/step - loss: 0.5562 - accuracy: 0.7185\n",
            "Epoch 4/10\n",
            "8232/8232 [==============================] - 144s 17ms/step - loss: 0.5230 - accuracy: 0.7404\n",
            "Epoch 5/10\n",
            "8232/8232 [==============================] - 149s 18ms/step - loss: 0.5054 - accuracy: 0.7524\n",
            "Epoch 6/10\n",
            "8232/8232 [==============================] - 147s 18ms/step - loss: 0.4920 - accuracy: 0.7606\n",
            "Epoch 7/10\n",
            "8232/8232 [==============================] - 141s 17ms/step - loss: 0.4839 - accuracy: 0.7662\n",
            "Epoch 8/10\n",
            "8232/8232 [==============================] - 143s 17ms/step - loss: 0.4770 - accuracy: 0.7689\n",
            "Epoch 9/10\n",
            "8232/8232 [==============================] - 142s 17ms/step - loss: 0.4713 - accuracy: 0.7711\n",
            "Epoch 10/10\n",
            "8232/8232 [==============================] - 140s 17ms/step - loss: 0.4667 - accuracy: 0.7739\n",
            "1000/1000 [==============================] - 12s 11ms/step - loss: 0.4895 - accuracy: 0.7619\n",
            "\n",
            "\n",
            "Test Loss 0.48947155475616455, Test Accuracy 0.7619166374206543\n"
          ]
        }
      ]
    }
  ]
}