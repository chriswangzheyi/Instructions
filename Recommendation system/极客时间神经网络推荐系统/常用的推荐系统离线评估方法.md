# 常用的推荐系统离线评估方法



## 离线评估的主要方法



### Holdout 检验、交叉检验和自助法



Holdout 检验是最基础，最常用的离线评估方法，它将原始的样本集合随机划分为训练集和测试集两部分，所以 **Holdout 检验的关键词就是“随机”。**举例来说，对于一个推荐模型，我们可以把样本按照 70%-30% 的比例随机分成两部分。其中，70% 的样本用于模型的训练，30% 的样本用于模型的评估。



虽然 Holdout 检验很简单实用，但它的缺点也很明显，就是评估的结果有一定随机性，因为训练集和验证集的划分是随机的，所以如果只进行少量的 Holdout 检验，得到的评估指标会存在一定的波动。那为了消除这种随机性，我们就要使用“交叉检验”的方法。



为了进行交叉检验，我们需要先将全部样本划分成 k 个大小相等的样本子集，然后依次遍历这 k 个子集，每次把当前遍历到的子集作为验证集，其余所有的子集作为训练集，这样依次进行 k 次模型的训练和评估。最后，我们再将所有 k 次评估指标的平均值作为最终的评估指标。在我们的实践中，k 经常取 10，也就是依次进行 10 次检验然后取指标均值。



不管是 Holdout 检验还是交叉检验，都是基于划分训练集和测试集的方法进行模型评估的。然而，当样本规模比较小时，将样本集进行划分会让训练集进一步减小，这往往会影响模型的训练效果。那有没有能维持训练集样本规模的验证方法呢？



“自助法”就可以在一定程度上解决这个问题。**自助法（Bootstrap）是基于自助采样的检验方法**，它的主要过程是：对于总数为 n 的样本集合，我们先进行 n 次有放回地随机抽样，得到大小为 n 的训练集。在 n 次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，我们再将这些没有被抽出的样本作为验证集进行模型验证，这就是自助法的验证过程。



自主法能够保持训练集的规模，但是它的缺点也很明显，它其实改变了原有数据的分布，有可能让模型产生一定程度的偏差。



### 时间切割



如果我们在 t 时刻进行模型预测，那么 t+1 时刻的信息就是未来信息。在构建特征工程的时候，我们要避免引入“未来信息”。

为了防止这类“信息穿越”导致的模型作弊现象发生，我们一般会使用时间切割的方案去划分训练集和测试集。

比如，你一共处理了 30 天的样本，从第 25 天末开始切割，前 25 天的样本作为训练集，后 5 天的样本作为测试集，这样我们就从根源上切断了引入“未来信息”的可能。



### 离线 Replay



时间切割的方法虽然能避免“信息穿越”，但也不是没有缺点的。它的缺点就在于整个评估过程是静态的，模型不会随着评估的进行而更新，这显然是不符合事实的。



就拿我们刚才举的例子来说，用前 25 天的数据做训练集，用后 5 天的数据做测试集。如果在生产环境中，模型是日更新的，那后 5 天的评测过程就不准确，因为在离线测试中，我们并没有在后 5 天的评测过程中做到日更模型。



可以在离线状态下对线上更新过程进行仿真，让整个评估过程“动”起来。**业界把这样离线仿真式的评估方式叫做离线 Replay。**



下图就是动态的 Replay 评估法与静态的时间分割评估法的对比示意图。我们可以看到，“Replay 评估方法”先根据产生时间对测试样本，由早到晚地进行排序，再让模型根据样本时间的先后进行预测。在模型更新的时间点上，模型需要增量学习更新时间点前的测试样本，更新模型后，再继续评估更新点之后的样本。



![](Images/74.webp)

Replay 评估的过程更接近于真实的线上环境，因为它在线下还原了模型在线上的更新、预估过程。这也让 Replay 方法的评估结果更加权威可信，毕竟，我们最终的目标是让模型在线上产生更好的效果。



Replay 评估方法也有弊端，因为它需要在评估过程中不断更新模型，这让评估过程的工程实现难度加大，因为包含了模型训练的时间，所以整个评估过程的总时长也会加长，影响评估和调参的效率。到底是要评估的准确性，还是要评估的效率，这又是一个需要权衡的问题。



### 基于 Spark 的离线评估方法实践

熟悉了离线环节的主要模型评估方法，就又到了实践的环节。其实，无论是基于 Python 的 TensorFlow 还是基于 Scala 的 Spark，都有很多支持离线评估的库，这里我们选择了 Spark 进行实践，主要是因为在业界数据集很大的情况下，Spark 在分布式环境下划分训练集和测试集的效率是最高的。



看一下如何使用 Spark 实现 Holdout 检验、交叉检验和时间切割评估法。至于另外两种方法，由于自助法不太常用，离线 Replay 又涉及过多的附加模块，我们暂时就不在项目里实现。



用 Spark 随机划分测试集和训练集。它的关键代码只有下面这一行，就是利用 randomSplit 函数把全量样本 samples 按比例分割成 trainingSamples 和 testSamples。

```scala
val Array(trainingSamples, testSamples) = samples.randomSplit(Array(0.9, 0.1))
```



实现交叉检验的过程相对比较复杂，好在，Spark 已经提供了交叉检验的接口可以直接使用:



```scala
val cv = new CrossValidator()
  .setEstimator(modelPipeline)
  .setEvaluator(new BinaryClassificationEvaluator)
  .setEstimatorParamMaps(paramGrid)
  .setNumFolds(10)  // Use 3+ in practice
val cvModel = cv.fit(training)
```

这段代码中有三个关键参数，一是 setEstimator，这是我们要评估的对象，它需要把我们构建的模型 pipeline 设置进去；二是 setEvaluator，它用来设置评估所用的方法和指标；三是 setNumFolds，它设置的是交叉检验中 k 的值，也就是把样本分成多少份用于交叉检验。本质上 Spark 的 CrossValidator 其实是通过交叉检验来选择模型的最优参数，但也可以通过模型中 cvModel.avgMetrics 参数查看模型的评估指标。



**实现时间切割方法。**既然是要按时间划分，如果你知道样本的时间跨度，直接用 where 语句就可以把训练集和测试集划分开了



如果你不知道样本的时间跨度，就要按照时间求取样本的分位数。具体来说就是，通过 Spark 的 approxQuantile 函数，我们可以找到划分样本集为 8:2 的训练集和测试集的时间戳的值。



```scala
//找到时间切割点
val quantile = smallSamples.stat.approxQuantile("timestampLong", Array(0.8), 0.05)
val splitTimestamp = quantile.apply(0)
//切割样本为训练集和测试集
val training = smallSamples.where(col("timestampLong") <= splitTimestamp).drop("timestampLong")
val test = smallSamples.where(col("timestampLong") > splitTimestamp).drop("timestampLong")

```

代码解释：



**计算时间戳的分位数**：

```scala
val quantile = smallSamples.stat.approxQuantile("timestampLong", Array(0.8), 0.05)
```

- `"timestampLong"`：我们关注的列名。
- `Array(0.8)`：我们要计算的分位数，这里是 80% 分位数，即时间戳值小于或等于该分位数的数据占全部数据的 80%。
- `0.05`：这是精确度参数，表示算法在 80% 分位数的估计值上的允许误差范围是实际值的 5%。

**存储分位数值作为分割点**：

```scala
val splitTimestamp = quantile.apply(0)
```

**切割样本为训练集**：

```scala
val training = smallSamples.where(col("timestampLong") <= splitTimestamp).drop("timestampLong")
```

这里选取 `timestampLong` 小于或等于 `splitTimestamp` 的所有行，作为训练集。`.drop("timestampLong")` 表示在最终的训练集中不包含 `timestampLong` 列。

**切割样本为测试集**：

```scala
val test = smallSamples.where(col("timestampLong") > splitTimestamp).drop("timestampLong")
```

这行代码选取 `timestampLong` 大于 `splitTimestamp` 的所有行，作为测试集。同样，`.drop("timestampLong")` 表示在最终的测试集中不包含 `timestampLong` 列。