# 强化学习的数学基础：马尔可夫决策过程



## 🧍‍♂️ 生活中的例子：你在迷宫里找出口



假设你是一个玩家，被困在一个迷宫中。
 每一时刻你都要选择一个动作，比如：

- 向上走
- 向下走
- 向左走
- 向右走

当你走完一步后：

- 你会进入新的位置（状态）；
- 可能得到奖励（比如找到出口奖励 +10，撞墙 -1）；
- 然后继续做下一步。

这整个过程，就是一个马尔可夫决策过程（MDP）。



## 🧱 MDP 的五个关键组成部分



| 元素                                      | 含义               | 例子（迷宫游戏）           |
| ----------------------------------------- | ------------------ | -------------------------- |
| **S：状态（State）**                      | 你现在在哪         | 当前你在迷宫的第(3,4)格    |
| **A：动作（Action）**                     | 你可以做什么       | 向上、下、左、右走         |
| **P：转移概率（Transition Probability）** | 做动作后，会到哪里 | 向右走有90%成功、10%滑倒   |
| **R：奖励（Reward）**                     | 每一步的回报       | 找到出口 +10，撞墙 -1      |
| **γ：折扣因子（Discount factor）**        | 未来奖励的重要性   | 0.9 表示“越早拿到奖励越好” |





## 🔁 “马尔可夫”是什么意思？

“马尔可夫”这个词的意思是：

> 未来只取决于**当前状态**，而与**过去经历**无关。

比如：

> 你现在在迷宫第(3,4)格，只要知道这一格在哪，就能决定下一步的策略；
>  不需要知道你之前是怎么走来的。

这就叫做**马尔可夫性质（Markov Property）**





## 决策过程的目标是什么？

智能体的目标是：

> 找到一个策略（Policy），告诉自己在每个状态下该怎么行动，
>  从而**让长期的总奖励最高**。

比如：

> “在空地上尽量往右走，一旦看到墙就绕开”
>  这可能是一种策略（policy）。



## 🧮 数学上怎么写？

一个 MDP 通常写成一个五元组：
$$
\text{MDP} = (S, A, P, R, \gamma)
$$

其中：
- \( S \)：状态集合（State）
- \( A \)：动作集合（Action）
- \( P(s'|s,a) \)：状态转移概率，表示在状态 \( s \) 采取动作 \( a \) 后转移到新状态 \( s' \) 的概率
- \( R(s,a) \)：奖励函数，表示在状态 \( s \) 下执行动作 \( a \) 获得的即时奖励
- \( \gamma \)：折扣因子（Discount Factor），用于平衡“当前奖励”和“未来奖励”的重要性





