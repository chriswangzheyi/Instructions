# Flink面试题

## Flink 如何处理反压？

### 反压出现的场景
**数据的消费速度小于数据的生产速度。**
反压经常出现在促销、热门活动等场景。短时间内流量陡增造成数据的堆积或者消费速度变慢。

### 反压监控方法

**通过Flink Web UI发现反压问题**
Flink 的 TaskManager 会每隔 50 ms 触发一次反压状态监测，共监测 100 次，并将计算结果反馈给 JobManager，最后由 JobManager 进行计算反压的比例，然后进行展示。

### 反压问题定位和处理

Flink会因为数据堆积和处理速度变慢导致checkpoint超时，而checkpoint是Flink保证数据一致性的关键所在，最终会导致数据的不一致发生。

* 数据倾斜：可以在 Flink 的后台管理页面看到每个 Task 处理数据的大小。当数据倾斜出现时，通常是简单地使用类似 KeyBy 等分组聚合函数导致的，需要用户将热点 Key 进行预处理，降低或者消除热点 Key 的影

* GC：不合理的设置 TaskManager 的垃圾回收参数会导致严重的 GC 问题，我们可以通过 -XX:+PrintGCDetails 参数查看 GC 的日志。

* 代码本身：开发者错误地使用 Flink 算子，没有深入了解算子的实现机制导致性能问题。我们可以通过查看运行机器节点的 CPU 和内存情况定位问题。

## 如何处理生产环境中的数据倾斜问题？

业务上要尽量避免热点 key 的设计，例如我们可以把北京、上海等热点城市分成不同的区域，并进行单独处理；

技术上出现热点时，要调整方案打散原来的 key，避免直接聚合；此外 Flink 还提供了大量的功能可以避免数据倾斜。

### Flink 任务数据倾斜场景和解决方案

#### 两阶段聚合解决 KeyBy 热点：

首先把分组的 key 打散，比如加随机后缀；
对打散后的数据进行聚合；
把打散的 key 还原为真正的 key；

#### GroupBy + Aggregation 分组聚合热点问题:

将SQL 拆成了内外两层，第一层通过随机打散 100 份的方式减少数据热点

#### Flink 消费 Kafka 上下游并行度不一致导致的数据倾斜


## flink海量数据高效去重

* 基于布隆过滤器（BloomFilter）
* 基于BitMap
* 基于外部数据库


## Flink 任务出现很高的延迟，你会如何入手解决类似问题

在 Flink 的后台任务管理中，可以看到 Flink 的哪个算子和 task 出现了反压；

资源调优和算子调优：资源调优即对作业中的 Operator 并发数（Parallelism）、CPU（Core）、堆内存（Heap_memory）等参数进行调优；

作业参数调优：并行度的设置、State 的设置、Checkpoint 的设置。


## exactly-once 的保证

端到端的 exactly-once 对 sink 要求比较高，具体实现主要有幂等写入和 事务性写入两种方式。幂等写入的场景依赖于业务逻辑，更常见的是用事务性写入。 而事务性写入又有​​预写日志（WAL）​​​和​​两阶段提交（2PC）​​两种方式。

如果外部系统不支持事务，那么可以用预写日志的方式，把结果数据先当成状态保存，然后在收到 checkpoint 完成的通知时，一次性写入 sink 系统。
