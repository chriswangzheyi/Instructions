# 1.Hadoop环境部署（阿里云版）

参考：https://blog.csdn.net/weixin_42445820/article/details/104568421?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522158882072519724848309881%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=158882072519724848309881&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_v25-1


## 阿里云版跟普通版本的区别


###阿里云

core-site.xml，yarn-site.xml 的defaultFS 和hostname 中填写阿里云的内网ip地址。

### 普通centos

core-site.xml，yarn-site.xml 中填写主机的ip地址。

## 修改Hostname

	sudo hostnamectl set-hostname wangzheyi

## 配置映射

	vi /etc/hosts

## 安装JDK

	yum install java-1.8.0-openjdk* -y;

查看安装路径

	which java

	ls -lrt /usr/bin/java（也就是上一步查询出来的路径）

	ls -lrt /etc/alternatives/java（也就是上一步查询出来的路径）

从路径中可以看到在jvm目录下，

	/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64


插入

vi /etc/profile

	export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64
	export JRE_HOME=$JAVA_HOME/jre  
	export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
	export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib


## 安装Hadoop

	tar -xvf hadoop-2.10.0.tar.gz

### 配置hadoop环境变量

vi /etc/profile

插入:

	HADOOP_HOME=/root/hadoop-2.10.0
	PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH


刷新：

	source /etc/profile

验证：

	hadoop version


## 配置ssh免密登录

	cd /root/.ssh

	ssh-keygen

一路回车之后在/root/.ssh下会生成两个文件，

	ssh-copy-id ‘本机ip’
	例如：ssh-copy-id 47.112.142.231


添加映射

	47.112.142.231 wangzheyi


## 修改hadoop配置文件

	cd /root/hadoop-2.10.0/etc/hadoop

修改hadoop-env.sh配置文件，添加jdk路径

	export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64


### 进入core-site.xml中修改或添加以下信息

	<configuration>
	    <property>
	            <name>fs.defaultFS</name>
	            <value>hdfs://172.18.156.87:9000</value>
	    </property>
	    <property>
	            <name>hadoop.tmp.dir</name>
	            <value>/root/hadoop-2.10.0/data/tmp</value>
	    </property>
	    <property>
	            <name>hadoop.http.staticuser.user</name>
	            <value>root</value>
	    </property>
	</configuration>



### 进入hdfs-site.xml中修改或添加以下信息

	<configuration>
	        <property>
	                <name>dfs.replication</name>
	                <value>1</value>
	        </property>
	        <property>
	                <name>dfs.permissions</name>
	                <value>false</value>
	        </property>
			<property>
		        <name>dfs.namenode.name.dir</name>
		        <value>file:///root/hadoop-2.10.0/datas/namenode/namenodedatas</value>
		    </property>
		    <property>
		        <name>dfs.datanode.data.dir</name>
		        <value>file://root/hadoop-2.10.0/datas/datanode/datanodeDatas</value>
		    </property>
	</configuration>


### 进入mapred-site.xml中修改或添加以下信息

	cp mapred-site.xml.template mapred-site.xml
	vim mapred-site.xml

插入

	<configuration>
		<property>
	    	<name>mapreduce.framework.name</name>
	       	<value>yarn</value>
	    </property>
	</configuration>


### 进入yarn-site.xml中修改或添加以下信息

	<configuration>
	
	<!-- Site specific YARN configuration properties -->
		<property>
	       <name>yarn.resourcemanager.hostname</name>
	       <value>172.18.156.87</value>
		</property>
		<property>
	       <name>yarn.nodemanager.aux-services</name>
	       <value>mapreduce_shuffle</value>
		</property>
		<property>
	       <name>yarn.nodemanager.resource.memory-mb</name>
	       <value>3072</value>
		</property>
	</configuration>


## 关闭防火墙

	systemctl stop firewalld.service  关闭防火墙
	systemctl disable firewalld.service   禁止开机启动
	firewall-cmd --state 查看防火墙状态



## 初始化

	cd /root/hadoop-2.10.0/bin
	./hdfs namenode -format

	cd /root/hadoop-2.10.0/sbin/ 
	start-all.sh

查看是否成功


	jps


## 如果出现Permission denied (publickey,gssapi-keyex,gssapi-with-mic).

	sudo vim /etc/ssh/sshd_config
	增加如下修改
	PasswordAuthentication yes
	

	sudo systemctl restart sshd

如果没有设置密码

	passwd root



### 如果datanode 启动不了

	rm -rf /root/hadoop-2.10.0/data/tmp/dfs/data
	
	cd /root/hadoop-2.10.0/sbin/
	hadoop-daemon.sh start datanode




## 测试

在hsfs上创建一个文件夹：

	hadoop fs -mkdir /input

查看该文件夹：

	hadoop fs -ls /